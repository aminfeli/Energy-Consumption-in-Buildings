import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
import pmdarima as pm
from sklearn.metrics import mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import StandardScaler
import seaborn as sns

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
df = pd.read_csv("D:/third semester/Casystudy2/2-Dataset/electricity_consumption-2.csv")
print(df.info())
print(df.head())
print(df.describe())

# Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ú¯Ù…Ø´Ø¯Ù‡
missing_values = df.isnull().sum()
print("Missing values:\n", missing_values)

total_missing = missing_values.sum()
if total_missing > 0:
    print(f"Total missing values: {total_missing}")
    df = df.dropna()
    print("Missing values deleted.")
else:
    print("No missing values in the dataset.")

# Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± ØªÚ©Ø±Ø§Ø±ÛŒ
duplicates_count = df.duplicated().sum()
if duplicates_count > 0:
    print(f"Duplicates are present. Total duplicate rows: {duplicates_count}")
    df = df.drop_duplicates()
    print("Duplicates deleted.")
else:
    print("No duplicates are present in the dataset.")

##################################
import matplotlib.pyplot as plt
import seaborn as sns

# Ø§Ù†ØªØ®Ø§Ø¨ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
numeric_df = df.select_dtypes(include=[np.number])

# Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø¨Ø§ Z-Score
from scipy.stats import zscore
z_scores = np.abs(zscore(numeric_df))
threshold = 3
non_outliers_mask = (z_scores < threshold).all(axis=1)
print(f"ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø­Ø°Ùâ€ŒØ´Ø¯Ù‡: {(~non_outliers_mask).sum()}")
df = df[non_outliers_mask]
numeric_df = df.select_dtypes(include=[np.number])  # Ø¨Ø§Ø²ØªØ¹Ø±ÛŒÙ Ù¾Ø³ Ø§Ø² Ø­Ø°Ù

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ù¾ÛŒØ±Ø³ÙˆÙ†
corr_matrix = numeric_df.corr()

# Ú†Ø§Ù¾ Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
print("Correlation matrix:")
print(corr_matrix)

# ØªØ±Ø³ÛŒÙ… heatmap Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
plt.figure(figsize=(15, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', cbar=True, square=True, linewidths=0.5)
plt.title("Correlation Heatmap of Numerical Features")
plt.show()

# Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¬ÙØªâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø®ÛŒÙ„ÛŒ Ø¨Ø§Ù„Ø§ (Ù…Ø«Ù„Ø§Ù‹ > 0.85)
threshold = 0.85
high_corr = []

for i in range(len(corr_matrix.columns)):
    for j in range(i):
        if abs(corr_matrix.iloc[i, j]) > threshold:
            colname_i = corr_matrix.columns[i]
            colname_j = corr_matrix.columns[j]
            corr_value = corr_matrix.iloc[i, j]
            high_corr.append((colname_i, colname_j, corr_value))

print(f"\nPairs with correlation higher than {threshold}:")
for pair in high_corr:
    print(f"{pair[0]} <--> {pair[1]} : correlation = {pair[2]:.2f}")
#####################################################################3XGBOOST Algorirhim
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from xgboost import XGBRegressor

# Ù‡Ø¯Ù Ù…Ø§: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ 'Energy Consumption (kWh)'
target = 'Energy Consumption (kWh)'

# Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (ØªÙ…Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø¨Ù‡ Ø¬Ø² Ù‡Ø¯Ù)
features = numeric_df.drop(columns=[target]).columns
X = df[features]
y = df[target]

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ØªØ¹Ø±ÛŒÙ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ XGBoost
model = XGBRegressor(n_estimators=100, learning_rate=0.2, max_depth=5, random_state=42)
model.fit(X_train, y_train)

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
y_pred = model.predict(X_test)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Model Evaluation Metrics:")
print(f"  MAE: {mae:.4f}")
print(f"  MSE: {mse:.4f}")
print(f"  R2 Score: {r2:.4f}")
##########################################SHAP
import shap

# Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ØªÙˆØ¶ÛŒØ­â€ŒØ¯Ù‡Ù†Ø¯Ù‡ SHAP Ø¨Ø±Ø§ÛŒ XGBoost
explainer = shap.Explainer(model)

# Ú¯Ø±ÙØªÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± shap Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª
shap_values = explainer(X_test)

# Ù†Ù…ÙˆØ¯Ø§Ø± Ø®Ù„Ø§ØµÙ‡ ØªØ£Ø«ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
shap.summary_plot(shap_values, X_test)

# Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ£Ø«ÛŒØ± ÛŒÚ© ÙˆÛŒÚ˜Ú¯ÛŒ Ø®Ø§Øµ (Ù…Ø«Ù„Ø§Ù‹ 'HVAC Consumption (kWh)')
# shap.dependence_plot('HVAC Consumption (kWh)', shap_values.values, X_test)

###################################################################################Random Forest
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù‡Ø¯Ù
target = 'Energy Consumption (kWh)'
features = numeric_df.drop(columns=[target]).columns
X = df[features]
y = df[target]

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ØªØ¹Ø±ÛŒÙ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Random Forest
rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
rf_model.fit(X_train, y_train)

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
y_pred = rf_model.predict(X_test)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("ğŸ” Random Forest Evaluation Metrics:")
print(f"  MAE: {mae:.4f}")
print(f"  MSE: {mse:.4f}")
print(f"  RÂ² Score: {r2:.4f}")

#########################################Shap - random forest

import shap

# Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Explainer Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Random Forest
explainer = shap.Explainer(rf_model, X_test)

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± shap
shap_values = explainer(X_test)

# Ù†Ù…ÙˆØ¯Ø§Ø± summary Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ ØªØ£Ø«ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
shap.summary_plot(shap_values, X_test)

# [Ø§Ø®ØªÛŒØ§Ø±ÛŒ] Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ£Ø«ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒ Ø®Ø§Øµ:
# shap.dependence_plot("HVAC Consumption (kWh)", shap_values.values, X_test)
