import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pmdarima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from scipy.stats import zscore

# ======================== Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ ==========================
df = pd.read_csv("D:/third semester/Casystudy2/2-Dataset/electricity_consumption-2.csv")

# ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª Ø³ØªÙˆÙ† Timestamp Ùˆ ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø²Ù…Ø§Ù†ÛŒ
df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')
df.dropna(subset=['Timestamp'], inplace=True)
df.sort_values('Timestamp', inplace=True)
df.set_index('Timestamp', inplace=True)      # Ø§ÛŒÙ† Ø®Ø· Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù… Ø§Ø³Øª
df = df.asfreq('H')  # ØªØ¹ÛŒÛŒÙ† ÙØ±Ú©Ø§Ù†Ø³ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ø§Ø¹ØªÛŒ

# Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
df = df.drop_duplicates()

# Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø¨Ø§ z-score ÙÙ‚Ø· Ø±ÙˆÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
numeric_df = df.select_dtypes(include=[np.number])
z_scores = np.abs(zscore(numeric_df))
df = df[(z_scores < 3).all(axis=1)]

# ======================== ØªØ¹ÛŒÛŒÙ† Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ ==========================
target_col = 'Energy Consumption (kWh)'

# ØªÙ…Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø¨Ù‡ Ø¬Ø² Ù‡Ø¯Ù Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙˆÛŒÚ˜Ú¯ÛŒ (exogenous variables)
features = df.select_dtypes(include=[np.number]).columns.drop(target_col)

X = df[features]
y = df[target_col]

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª (Ø¨Ø±Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù†ØŒ 80 Ø¯Ø±ØµØ¯ Ø¢Ù…ÙˆØ²Ø´)
train_size = int(len(df) * 0.8)
X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]
y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]

# ======================== Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ SARIMA Ø¨Ø§ Auto ARIMA ==========================
auto_model = auto_arima(
    y_train,
    exogenous=X_train,
    seasonal=True,
    m=24,                # Ø¯ÙˆØ±Ù‡ ÙØµÙ„ÛŒ 24 Ø³Ø§Ø¹ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¹ØªÛŒ
    stepwise=True,
    suppress_warnings=True,
    trace=True
)

print(f"Best SARIMAX order: {auto_model.order}, seasonal_order: {auto_model.seasonal_order}")

# ======================== Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ SARIMAX ==========================
sarima_model = SARIMAX(
    y_train,
    exog=X_train,
    order=auto_model.order,
    seasonal_order=auto_model.seasonal_order
)
sarima_result = sarima_model.fit(disp=False)

# ======================== Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ SARIMAX ==========================
sarima_forecast = sarima_result.predict(
    start=len(y_train),
    end=len(y_train) + len(y_test) - 1,
    exog=X_test
)

# ======================== Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡â€ŒÙ‡Ø§ (Residuals) ==========================
residuals = y_test.values - sarima_forecast.values

# ======================== Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LSTM Ø±ÙˆÛŒ Residuals ==========================
scaler = MinMaxScaler()
residuals_scaled = scaler.fit_transform(residuals.reshape(-1, 1))

def create_sequences(data, seq_length):
    X_seq, y_seq = [], []
    for i in range(len(data) - seq_length):
        X_seq.append(data[i:i+seq_length])
        y_seq.append(data[i+seq_length])
    return np.array(X_seq), np.array(y_seq)

seq_length = 10
X_lstm, y_lstm = create_sequences(residuals_scaled, seq_length)

split_lstm = int(len(X_lstm) * 0.8)
X_train_lstm, X_test_lstm = X_lstm[:split_lstm], X_lstm[split_lstm:]
y_train_lstm, y_test_lstm = y_lstm[:split_lstm], y_lstm[split_lstm:]

model_lstm = Sequential()
model_lstm.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))
model_lstm.add(Dense(1))
model_lstm.compile(optimizer='adam', loss='mse')
model_lstm.fit(X_train_lstm, y_train_lstm, epochs=20, verbose=1)

lstm_pred_scaled = model_lstm.predict(X_test_lstm)
lstm_pred = scaler.inverse_transform(lstm_pred_scaled)

# ======================== ØªØ±Ú©ÛŒØ¨ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ ==========================
sarima_aligned = sarima_forecast[-len(lstm_pred):].values
final_forecast = sarima_aligned + lstm_pred.flatten()

# ======================== Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ ==========================
true_values = y_test[-len(lstm_pred):].values
mae = mean_absolute_error(true_values, final_forecast)
mse = mean_squared_error(true_values, final_forecast)
r2 = r2_score(true_values, final_forecast)

print("\nğŸ” Hybrid SARIMA + LSTM Evaluation:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# ======================== ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø± ==========================
plt.figure(figsize=(14,6))
plt.plot(true_values, label='Actual')
plt.plot(sarima_aligned, label='SARIMA Forecast')
plt.plot(final_forecast, label='Hybrid Forecast (SARIMA + LSTM)', color='red')
plt.legend()
plt.title("Hybrid SARIMA + LSTM Forecasting")
plt.xlabel("Time Steps")
plt.ylabel("Energy Consumption (kWh)")
plt.show()
